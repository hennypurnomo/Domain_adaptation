{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Loading BSR training images\n",
      "Building train set...\n",
      "Processing example 0\n",
      "Processing example 1000\n",
      "Processing example 2000\n",
      "Processing example 3000\n",
      "Processing example 4000\n",
      "Processing example 5000\n",
      "Processing example 6000\n",
      "Processing example 7000\n",
      "Processing example 8000\n",
      "Processing example 9000\n",
      "Processing example 10000\n",
      "Processing example 11000\n",
      "Processing example 12000\n",
      "Processing example 13000\n",
      "Processing example 14000\n",
      "Processing example 15000\n",
      "Processing example 16000\n",
      "Processing example 17000\n",
      "Processing example 18000\n",
      "Processing example 19000\n",
      "Processing example 20000\n",
      "Processing example 21000\n",
      "Processing example 22000\n",
      "Processing example 23000\n",
      "Processing example 24000\n",
      "Processing example 25000\n",
      "Processing example 26000\n",
      "Processing example 27000\n",
      "Processing example 28000\n",
      "Processing example 29000\n",
      "Processing example 30000\n",
      "Processing example 31000\n",
      "Processing example 32000\n",
      "Processing example 33000\n",
      "Processing example 34000\n",
      "Processing example 35000\n",
      "Processing example 36000\n",
      "Processing example 37000\n",
      "Processing example 38000\n",
      "Processing example 39000\n",
      "Processing example 40000\n",
      "Processing example 41000\n",
      "Processing example 42000\n",
      "Processing example 43000\n",
      "Processing example 44000\n",
      "Processing example 45000\n",
      "Processing example 46000\n",
      "Processing example 47000\n",
      "Processing example 48000\n",
      "Processing example 49000\n",
      "Processing example 50000\n",
      "Processing example 51000\n",
      "Processing example 52000\n",
      "Processing example 53000\n",
      "Processing example 54000\n",
      "Building test set...\n",
      "Processing example 0\n",
      "Processing example 1000\n",
      "Processing example 2000\n",
      "Processing example 3000\n",
      "Processing example 4000\n",
      "Processing example 5000\n",
      "Processing example 6000\n",
      "Processing example 7000\n",
      "Processing example 8000\n",
      "Processing example 9000\n",
      "Building validation set...\n",
      "Processing example 0\n",
      "Processing example 1000\n",
      "Processing example 2000\n",
      "Processing example 3000\n",
      "Processing example 4000\n"
     ]
    }
   ],
   "source": [
    "# this code is from https://github.com/pumpikano/tf-dann, without any change\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tarfile\n",
    "import os\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import skimage\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# load MNIST data from tensorflow library\n",
    "mnist = input_data.read_data_sets('MNIST_data')\n",
    "\n",
    "# name of data.zip\n",
    "BST_PATH = 'BSR_bsds500.tgz'\n",
    "\n",
    "# number of methods for generating random numbers to call by class\n",
    "rand = np.random.RandomState(42)\n",
    "\n",
    "# open the zip or tar\n",
    "f = tarfile.open(BST_PATH)\n",
    "\n",
    "# storing the name files from training data\n",
    "train_files = []\n",
    "for name in f.getnames():\n",
    "    if name.startswith('BSR/BSDS500/data/images/train/'):\n",
    "        train_files.append(name)\n",
    "\n",
    "print('Loading BSR training images')\n",
    "\n",
    "# extract a member from archieve\n",
    "background_data = []\n",
    "for name in train_files:\n",
    "    try:\n",
    "        fp = f.extractfile(name)        # extract file\n",
    "        bg_img = skimage.io.imread(fp)  # load an image from file\n",
    "        background_data.append(bg_img)  # save data into list\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "\n",
    "def compose_image(digit, background):\n",
    "    \"\"\"Difference-blend a digit and a random patch from a background image.\"\"\"\n",
    "    w, h, _ = background.shape\n",
    "    dw, dh, _ = digit.shape\n",
    "    x = np.random.randint(0, w - dw)\n",
    "    y = np.random.randint(0, h - dh)\n",
    "\n",
    "    bg = background[x:x + dw, y:y + dh]\n",
    "    return np.abs(bg - digit).astype(np.uint8)\n",
    "\n",
    "\n",
    "def mnist_to_img(x):\n",
    "    \"\"\"Binarize MNIST digit and convert to RGB.\"\"\"\n",
    "    x = (x > 0).astype(np.float32)\n",
    "    d = x.reshape([28, 28, 1]) * 255\n",
    "    return np.concatenate([d, d, d], 2)\n",
    "\n",
    "\n",
    "def create_mnistm(X):\n",
    "    \"\"\"\n",
    "    Give an array of MNIST digits, blend random background patches to\n",
    "    build the MNIST-M dataset as described in\n",
    "    http://jmlr.org/papers/volume17/15-239/15-239.pdf\n",
    "    \"\"\"\n",
    "    X_ = np.zeros([X.shape[0], 28, 28, 3], np.uint8)\n",
    "    for i in range(X.shape[0]):\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            print('Processing example', i)\n",
    "\n",
    "        bg_img = rand.choice(background_data)\n",
    "\n",
    "        d = mnist_to_img(X[i])\n",
    "        d = compose_image(d, bg_img)\n",
    "        X_[i] = d\n",
    "\n",
    "    return X_\n",
    "\n",
    "\n",
    "print('Building train set...')\n",
    "train = create_mnistm(mnist.train.images)\n",
    "print('Building test set...')\n",
    "test = create_mnistm(mnist.test.images)\n",
    "print('Building validation set...')\n",
    "valid = create_mnistm(mnist.validation.images)\n",
    "\n",
    "# Save dataset as pickle\n",
    "with open('mnistm_data.pkl', 'wb') as f:\n",
    "    pkl.dump({'train': train, 'test': test, 'valid': valid}, f, pkl.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# this main code by Ssamot from https://github.com/ssamot/infoGA/blob/master/mnist_snes_example.py\n",
    "# plot loss function from https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\n",
    "# loading data office-31 from Lyu Chaofan 1706987\n",
    
    "\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from dataSet import dataSet\n",
    "from timeit import default_timer as timer\n",
    "from keras import backend as K\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.models import Sequential\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras_helper import NNWeightHelper\n",
    "from snes import SNES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(model, X, y):\n",
    "    X_features = model.predict(X)\n",
    "    clf = RandomForestClassifier(n_estimators=10)\n",
    "    clf.fit(X_features, y)\n",
    "    y_pred = clf.predict(X_features)\n",
    "    return clf, y_pred\n",
    "def predict_classifier(model, clf, X):\n",
    "    X_features = model.predict(X)\n",
    "    return clf.predict(X_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "num_classes = 31\n",
    "\n",
    "# use just a small sample of the train set to test\n",
    "SAMPLE_SIZE = 300\n",
    "# how many different sets of weights ask() should return for evaluation\n",
    "POPULATION_SIZE = 10\n",
    "# how many times we will loop over ask()/tell()\n",
    "GENERATIONS = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Amazon_path = './Original_images/amazon/images'\n",
    "dslr_path   = './Original_images/dslr/images'\n",
    "webcam_path = './Original_images/webcam/images'\n",
    "\n",
    "paths = [Amazon_path, dslr_path, webcam_path]\n",
    "files = os.listdir(Amazon_path)\n",
    "labels = {}\n",
    "count  = 0\n",
    "for key in files:\n",
    "    a = {key : count}\n",
    "    labels.update(a)\n",
    "    count += 1\n",
    "# print (labels)\n",
    "\n",
    "images_path = []\n",
    "webcam = dataSet()\n",
    "dslr = dataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b73da12aa4a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mAmazon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mAmazon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msHape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Domain_adaptation/dataSet.py\u001b[0m in \u001b[0;36msHape\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msHape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mdatashape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatashape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatashape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for dirname in files:\n",
    "    images_name = os.listdir(Amazon_path + '/' + dirname)\n",
    "    for name in images_name:\n",
    "        Image_Path = Amazon_path + '/' + dirname + '/' + name\n",
    "        images_path.append(Image_Path)\n",
    "        image_data = cv2.imread(Image_Path)\n",
    "        image_data = cv2.resize(image_data, (img_rows, img_cols), interpolation=cv2.INTER_CUBIC)\n",
    "        image_data = image_data.reshape(img_rows, img_cols, 3)\n",
    "        Amazon.upData(image_data, labels[dirname], labels)\n",
    "        \n",
    "Amazon.sHape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirname in files:\n",
    "    images_name = os.listdir(dslr_path + '/' + dirname)\n",
    "    for name in images_name:\n",
    "        Image_Path = dslr_path + '/' + dirname + '/' + name\n",
    "        images_path.append(Image_Path)\n",
    "        image_data = cv2.imread(Image_Path)\n",
    "        image_data = cv2.resize(image_data, (img_rows, img_cols), interpolation=cv2.INTER_CUBIC)\n",
    "        image_data = image_data.reshape(img_rows, img_cols, 3)\n",
    "        dslr.upData(image_data, labels[dirname], labels)\n",
    "        \n",
    "dslr.sHape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data for label classifier\n",
    "x_test = webcam.data\n",
    "y_test = webcam.label\n",
    "x_train = dslr.data\n",
    "y_train = dslr.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 3)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 3)\n",
    "input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n\n",
    "# data for domain classifier\n",
    "x_domain = np.concatenate((x_train,x_test), axis = 0)\n",
    "y_domain = np.concatenate((np.zeros(y_train.shape[0]), np.ones(y_test.shape[0])),axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(5, 5),activation='relu',\n",
    "                 input_shape=(28,28,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "\n",
    "# this is irrelevant for what we want to achieve\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "print(\"compilation is over\")\n",
    "nnw = NNWeightHelper(model)\n",
    "weights = nnw.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of weights to evolve is:\", weights.shape)\n",
    "all_examples_indices = list(range(x_train.shape[0]))\n",
    "clf, _ = train_classifier(model, x_train, y_train)\n",
    "y_pred = predict_classifier(model, clf, x_test)\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Non-trained NN Test accuracy:', test_accuracy)\n",
    "# print('Test MSE:', test_mse)\n",
    "\n",
    "snes = SNES(weights, 1, POPULATION_SIZE)\n",
    "p = []\n",
    "for i in range(0, GENERATIONS):\n",
    "    start = timer()\n",
    "    asked = snes.ask()\n",
    "\n",
    "    # to be provided back to snes\n",
    "    told = []\n",
    "\n",
    "    # use a small number of training samples for speed purposes\n",
    "    subsample_indices = np.random.choice(all_examples_indices, size=SAMPLE_SIZE, replace=False)\n",
    "    # evaluate on another subset\n",
    "    subsample_indices_valid = np.random.choice(all_examples_indices, size=SAMPLE_SIZE + 1, replace=False)\n",
    "\n",
    "    # iterate over the population\n",
    "    for asked_j in asked:\n",
    "        # set nn weights\n",
    "        nnw.set_weights(asked_j)\n",
    "        # train the classifer and get back the predictions on the training data\n",
    "        clf, _ = train_classifier(model, x_train[subsample_indices], y_train[subsample_indices])\n",
    "        # train the domain classifier and get back the predictions on the training data\n",
    "        clf2, _ = train_classifier(model, x_domain[subsample_indices], y_domain[subsample_indices])\n",
    "        \n",
    "        # calculate the label predictions on a different set\n",
    "        y_pred = predict_classifier(model, clf, x_train[subsample_indices_valid])\n",
    "        score = accuracy_score(y_train[subsample_indices_valid], y_pred)\n",
    "\n",
    "        # calculate the domain predictions on a different set\n",
    "        y_pred1 = predict_classifier(model, clf, x_domain[subsample_indices_valid])\n",
    "        score1 = accuracy_score(y_domain[subsample_indices_valid], y_pred1)\n",
    "        total = (score+(2*-score1))\n",
    "        told.append(total)\n",
    "\n",
    "    temp = snes.tell(asked, told)\n",
    "    p.append(temp)\n",
    "    end = timer()\n",
    "    print(\"It took\", end - start, \"seconds to complete generation\", i + 1)\n",
    "    \n",
    "nnw.set_weights(snes.center)\n",
    "\n",
    "# predict on source data\n",
    "clf, _ = train_classifier(model, x_train, y_train)\n",
    "y_pred = predict_classifier(model, clf, x_train)\n",
    "test_accuracy = accuracy_score(y_train, y_pred)\n",
    "print('Test accuracy on source:', test_accuracy)\n",
    "\n",
    "# predict on target data\n",
    "\n",
    "y_pred1 = predict_classifier(model, clf, x_test)\n",
    "test_accuracy1 = accuracy_score(y_test, y_pred1)\n",
    "print('Test accuracy on target:', test_accuracy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(p)\n",
    "plt.title('Loss Plot Amazon - webcam')\n",
    "plt.xlabel('generation')\n",
    "plt.ylabel('value')\n",
    "plt.savefig('Plot_amazon_dslr.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

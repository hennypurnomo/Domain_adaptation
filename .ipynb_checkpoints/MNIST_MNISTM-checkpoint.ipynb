{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# this main code by Ssamot from https://github.com/ssamot/infoGA/blob/master/mnist_snes_example.py\n",
    "# plot loss function from https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\n",
    "\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from keras import backend as K\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.models import Sequential\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras_helper import NNWeightHelper\n",
    "from keras.utils import np_utils\n",
    "from snes import SNES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use just a small sample of the train set to test\n",
    "SAMPLE_SIZE = 400\n",
    "# how many different sets of weights ask() should return for evaluation\n",
    "POPULATION_SIZE = 10\n",
    "# how many times we will loop over ask()/tell()\n",
    "GENERATIONS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(model, X, y):\n",
    "    X_features = model.predict(X)\n",
    "    clf = RandomForestClassifier(n_estimators = 10)\n",
    "    clf.fit(X_features, y)\n",
    "    y_pred = clf.predict(X_features)\n",
    "    return clf, y_pred\n",
    "\n",
    "\n",
    "def predict_classifier(model, clf, X):\n",
    "    X_features = model.predict(X)\n",
    "    return clf.predict(X_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset from keras for source domain\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 28, 28, 1).astype(np.uint8) * 255\n",
    "x_train = np.concatenate([x_train, x_train, x_train], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST-M dataset for target domain\n",
    "mnistm = pkl.load(open('mnistm_data.pkl', 'rb'))\n",
    "mnistm_train = mnistm['train']\n",
    "mnistm_test = mnistm['test']\n",
    "mnistm_valid = mnistm['valid']\n",
    "x_test=mnistm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create part data for domain classifier, combination from source and target data\n",
    "x_domain=np.concatenate((x_train,x_test), axis =0)\n",
    "y_domain = np.concatenate((np.zeros(y_train.shape[0]), np.ones(y_test.shape[0])),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data normalization\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compilation is over\n"
     ]
    }
   ],
   "source": [
    "# neural network architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(5, 5),activation='relu',\n",
    "                 input_shape=(28,28,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "\n",
    "# this is irrelevant for what we want to achieve\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "print(\"compilation is over\")\n",
    "nnw = NNWeightHelper(model)\n",
    "weights = nnw.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of weights to evolve is: (53714,)\n",
      "Non-trained NN Test accuracy: 0.1571\n",
      "Step 1.0 : -1.6034912718204488 best: -1.6034912718204488 10\n",
      "It took 9.596360042000015 seconds to complete generation 1\n",
      "Step 2.0 : -1.5860349127182045 best: -1.5860349127182045 10\n",
      "It took 9.631854506998934 seconds to complete generation 2\n",
      "Step 3.0 : -1.6359102244389028 best: -1.5860349127182045 10\n",
      "It took 9.632000059998973 seconds to complete generation 3\n",
      "Step 4.0 : -1.6109725685785536 best: -1.5860349127182045 10\n",
      "It took 9.631076171999666 seconds to complete generation 4\n",
      "Step 5.0 : -1.600997506234414 best: -1.5860349127182045 10\n",
      "It took 9.608430697000585 seconds to complete generation 5\n",
      "Step 6.0 : -1.600997506234414 best: -1.5860349127182045 10\n",
      "It took 9.678904500999124 seconds to complete generation 6\n",
      "Step 7.0 : -1.5860349127182045 best: -1.5860349127182045 10\n",
      "It took 9.643454027000189 seconds to complete generation 7\n",
      "Step 8.0 : -1.5785536159600997 best: -1.5785536159600997 10\n",
      "It took 11.121773504000885 seconds to complete generation 8\n",
      "Step 9.0 : -1.598503740648379 best: -1.5785536159600997 10\n",
      "It took 9.618740848998641 seconds to complete generation 9\n",
      "Step 10.0 : -1.6034912718204488 best: -1.5785536159600997 10\n",
      "It took 9.650098186999458 seconds to complete generation 10\n",
      "Step 11.0 : -1.5760598503740648 best: -1.5760598503740648 10\n",
      "It took 9.62877396499971 seconds to complete generation 11\n",
      "Step 12.0 : -1.5810473815461346 best: -1.5760598503740648 10\n",
      "It took 9.695638478999172 seconds to complete generation 12\n",
      "Step 13.0 : -1.5561097256857854 best: -1.5561097256857854 10\n",
      "It took 9.620232401000976 seconds to complete generation 13\n",
      "Step 14.0 : -1.5486284289276808 best: -1.5486284289276808 10\n",
      "It took 9.891236080999079 seconds to complete generation 14\n",
      "Step 15.0 : -1.5885286783042394 best: -1.5486284289276808 10\n",
      "It took 10.337814288001027 seconds to complete generation 15\n",
      "Step 16.0 : -1.5635910224438903 best: -1.5486284289276808 10\n",
      "It took 9.62766791300055 seconds to complete generation 16\n",
      "Step 17.0 : -1.5610972568578554 best: -1.5486284289276808 10\n",
      "It took 9.579113951000181 seconds to complete generation 17\n",
      "Step 18.0 : -1.5561097256857854 best: -1.5486284289276808 10\n",
      "It took 9.661193392999849 seconds to complete generation 18\n",
      "Step 19.0 : -1.5635910224438903 best: -1.5486284289276808 10\n",
      "It took 9.627622091000376 seconds to complete generation 19\n",
      "Step 20.0 : -1.5336658354114714 best: -1.5336658354114714 10\n",
      "It took 10.103814432000945 seconds to complete generation 20\n",
      "Step 21.0 : -1.571072319201995 best: -1.5336658354114714 10\n",
      "It took 9.602002473000539 seconds to complete generation 21\n",
      "Step 22.0 : -1.513715710723192 best: -1.513715710723192 10\n",
      "It took 9.620347448000757 seconds to complete generation 22\n",
      "Step 23.0 : -1.5261845386533666 best: -1.513715710723192 10\n",
      "It took 9.665217409999968 seconds to complete generation 23\n",
      "Step 24.0 : -1.5610972568578554 best: -1.513715710723192 10\n",
      "It took 9.678299044999221 seconds to complete generation 24\n",
      "Step 25.0 : -1.5311720698254363 best: -1.513715710723192 10\n",
      "It took 9.617446285999904 seconds to complete generation 25\n",
      "Step 26.0 : -1.5162094763092269 best: -1.513715710723192 10\n",
      "It took 9.631384407999576 seconds to complete generation 26\n",
      "Step 27.0 : -1.546134663341646 best: -1.513715710723192 10\n",
      "It took 10.173758013999759 seconds to complete generation 27\n",
      "Step 28.0 : -1.5336658354114714 best: -1.513715710723192 10\n",
      "It took 11.351583714000299 seconds to complete generation 28\n",
      "Step 29.0 : -1.5386533665835411 best: -1.513715710723192 10\n",
      "It took 9.635806356000103 seconds to complete generation 29\n",
      "Step 30.0 : -1.541147132169576 best: -1.513715710723192 10\n",
      "It took 9.698817927999698 seconds to complete generation 30\n",
      "Test accuracy on target: 0.1702\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of weights to evolve is:\", weights.shape)\n",
    "all_examples_indices = list(range(x_train.shape[0]))\n",
    "clf, _ = train_classifier(model, x_train, y_train)\n",
    "y_pred = predict_classifier(model, clf, x_test)\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Non-trained NN Test accuracy:', test_accuracy)\n",
    "# print('Test MSE:', test_mse)\n",
    "\n",
    "snes = SNES(weights, 1, POPULATION_SIZE)\n",
    "log = []\n",
    "for i in range(0, GENERATIONS):\n",
    "    start = timer()\n",
    "    asked = snes.ask()\n",
    "\n",
    "    # to be provided back to snes\n",
    "    told = []\n",
    "\n",
    "    # use a small number of training samples for speed purposes\n",
    "    subsample_indices = np.random.choice(all_examples_indices, size=SAMPLE_SIZE, replace=False)\n",
    "    # evaluate on another subset\n",
    "    subsample_indices_valid = np.random.choice(all_examples_indices, size=SAMPLE_SIZE + 1, replace=False)\n",
    "\n",
    "    # iterate over the population\n",
    "    for asked_j in asked:\n",
    "        # set nn weights\n",
    "        nnw.set_weights(asked_j)\n",
    "        # train the label classifer and get back the predictions on the training data\n",
    "        clf, _ = train_classifier(model, x_train[subsample_indices], y_train[subsample_indices])\n",
    "        # train the domain classifier and get back the predictions on the training data\n",
    "        clf2, _ = train_classifier(model, x_domain[subsample_indices], y_domain[subsample_indices])\n",
    "\n",
    "        # calculate the label predictions on a different set\n",
    "        y_pred = predict_classifier(model, clf, x_train[subsample_indices_valid])\n",
    "        score = accuracy_score(y_train[subsample_indices_valid], y_pred)\n",
    "\n",
    "        # calculate the domain predictions on a different set\n",
    "        y_pred2 = predict_classifier(model, clf2, x_domain[subsample_indices_valid])\n",
    "        score2 = accuracy_score(y_domain[subsample_indices_valid], y_pred2)\n",
    "        \n",
    "        # weighted score to give back to snes\n",
    "        total = (score+(2*-score2))\n",
    "        told.append(total)\n",
    "\n",
    "    temp = snes.tell(asked, told)\n",
    "    log.append(temp)\n",
    "    end = timer()\n",
    "    print(\"It took\", end - start, \"seconds to complete generation\", i + 1)\n",
    "    \n",
    "nnw.set_weights(snes.center)\n",
    "\n",
    "# predict on target data\n",
    "clf, _ = train_classifier(model, x_train, y_train)\n",
    "y_pred = predict_classifier(model, clf, x_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Test accuracy on target:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1e85c7ea58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print loss plot\n",
    "plt.plot(log)\n",
    "plt.title('Loss Plot MNIST and MNIST-M')\n",
    "plt.xlabel('generation')\n",
    "plt.ylabel('value')\n",
    "plt.savefig('Plot_mnist_mnistm.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

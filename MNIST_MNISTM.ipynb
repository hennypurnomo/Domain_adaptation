{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# this main code by Ssamot from https://github.com/ssamot/infoGA/blob/master/mnist_snes_example.py\n",
    "# plot loss function from https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\n",
    "\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from keras import backend as K\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.models import Sequential\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras_helper import NNWeightHelper\n",
    "from keras.utils import np_utils\n",
    "from snes import SNES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use just a small sample of the train set to test\n",
    "SAMPLE_SIZE = 300\n",
    "# how many different sets of weights ask() should return for evaluation\n",
    "POPULATION_SIZE = 10\n",
    "# how many times we will loop over ask()/tell()\n",
    "GENERATIONS = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(model, X, y):\n",
    "    X_features = model.predict(X)\n",
    "    clf = RandomForestClassifier(n_estimators = 10)\n",
    "    clf.fit(X_features, y)\n",
    "    y_pred = clf.predict(X_features)\n",
    "    return clf, y_pred\n",
    "\n",
    "\n",
    "def predict_classifier(model, clf, X):\n",
    "    X_features = model.predict(X)\n",
    "    return clf.predict(X_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset from keras for source domain\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 28, 28, 1).astype(np.uint8) * 255\n",
    "x_train = np.concatenate([x_train, x_train, x_train], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST-M dataset for target domain\n",
    "mnistm = pkl.load(open('mnistm_data.pkl', 'rb'))\n",
    "mnistm_train = mnistm['train']\n",
    "mnistm_test = mnistm['test']\n",
    "mnistm_valid = mnistm['valid']\n",
    "x_test=mnistm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create part data for domain classifier, combination from source and target data\n",
    "x_domain=np.concatenate((x_train,x_test), axis =0)\n",
    "y_domain = np.concatenate((np.zeros(y_train.shape[0]), np.ones(y_test.shape[0])),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data normalization\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compilation is over\n"
     ]
    }
   ],
   "source": [
    "# neural network architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',\n",
    "                 input_shape=(28,28,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='relu'))\n",
    "\n",
    "# this is irrelevant for what we want to achieve\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "print(\"compilation is over\")\n",
    "nnw = NNWeightHelper(model)\n",
    "weights = nnw.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of weights to evolve is: (18154,)\n",
      "Non-trained NN Test accuracy: 0.1369\n",
      "Step 1.0 : -2.6744186046511627 best: -2.6744186046511627 10\n",
      "It took 6.1904061999994155 seconds to complete generation 1\n",
      "Step 2.0 : -2.647840531561462 best: -2.647840531561462 10\n",
      "It took 5.778192820000186 seconds to complete generation 2\n",
      "Step 3.0 : -2.6744186046511627 best: -2.647840531561462 10\n",
      "It took 5.716539399001704 seconds to complete generation 3\n",
      "Step 4.0 : -2.661129568106312 best: -2.647840531561462 10\n",
      "It took 4.464206674998422 seconds to complete generation 4\n",
      "Step 5.0 : -2.681063122923588 best: -2.647840531561462 10\n",
      "It took 5.748341108001114 seconds to complete generation 5\n",
      "Step 6.0 : -2.6511627906976742 best: -2.647840531561462 10\n",
      "It took 6.145840399000008 seconds to complete generation 6\n",
      "Step 7.0 : -2.6279069767441863 best: -2.6279069767441863 10\n",
      "It took 5.507289995000974 seconds to complete generation 7\n",
      "Step 8.0 : -2.5780730897009967 best: -2.5780730897009967 10\n",
      "It took 5.542533429999821 seconds to complete generation 8\n",
      "Step 9.0 : -2.6245847176079735 best: -2.5780730897009967 10\n",
      "It took 5.8736956660013675 seconds to complete generation 9\n",
      "Step 10.0 : -2.6312292358803986 best: -2.5780730897009967 10\n",
      "It took 5.287442209999426 seconds to complete generation 10\n",
      "Step 11.0 : -2.5980066445182723 best: -2.5780730897009967 10\n",
      "It took 5.108124645999851 seconds to complete generation 11\n",
      "Step 12.0 : -2.647840531561462 best: -2.5780730897009967 10\n",
      "It took 6.39470513300148 seconds to complete generation 12\n",
      "Step 13.0 : -2.6312292358803986 best: -2.5780730897009967 10\n",
      "It took 5.595318430001498 seconds to complete generation 13\n",
      "Step 14.0 : -2.5980066445182723 best: -2.5780730897009967 10\n",
      "It took 5.687748512000326 seconds to complete generation 14\n",
      "Step 15.0 : -2.574750830564784 best: -2.574750830564784 10\n",
      "It took 4.500325699000314 seconds to complete generation 15\n",
      "Step 16.0 : -2.574750830564784 best: -2.574750830564784 10\n",
      "It took 4.935230461000174 seconds to complete generation 16\n",
      "Step 17.0 : -2.5714285714285716 best: -2.5714285714285716 10\n",
      "It took 7.94631555199885 seconds to complete generation 17\n",
      "Step 18.0 : -2.5813953488372094 best: -2.5714285714285716 10\n",
      "It took 8.180869092000648 seconds to complete generation 18\n",
      "Step 19.0 : -2.5780730897009967 best: -2.5714285714285716 10\n",
      "It took 9.272462966999228 seconds to complete generation 19\n",
      "Step 20.0 : -2.564784053156146 best: -2.564784053156146 10\n",
      "It took 6.936507240001447 seconds to complete generation 20\n",
      "Step 21.0 : -2.568106312292359 best: -2.564784053156146 10\n",
      "It took 7.659772208999129 seconds to complete generation 21\n",
      "Step 22.0 : -2.617940199335548 best: -2.564784053156146 10\n",
      "It took 6.34316633600065 seconds to complete generation 22\n",
      "Step 23.0 : -2.601328903654485 best: -2.564784053156146 10\n",
      "It took 5.398424772998624 seconds to complete generation 23\n",
      "Step 24.0 : -2.5946843853820596 best: -2.564784053156146 10\n",
      "It took 5.490456854000513 seconds to complete generation 24\n",
      "Step 25.0 : -2.5813953488372094 best: -2.564784053156146 10\n",
      "It took 8.182744960999116 seconds to complete generation 25\n",
      "Step 26.0 : -2.5946843853820596 best: -2.564784053156146 10\n",
      "It took 7.915933758999017 seconds to complete generation 26\n",
      "Step 27.0 : -2.5182724252491693 best: -2.5182724252491693 10\n",
      "It took 5.283114850000857 seconds to complete generation 27\n",
      "Step 28.0 : -2.60797342192691 best: -2.5182724252491693 10\n",
      "It took 4.807019263000257 seconds to complete generation 28\n",
      "Step 29.0 : -2.5847176079734218 best: -2.5182724252491693 10\n",
      "It took 5.136104466000688 seconds to complete generation 29\n",
      "Step 30.0 : -2.6279069767441863 best: -2.5182724252491693 10\n",
      "It took 4.636536313999386 seconds to complete generation 30\n",
      "Step 31.0 : -2.5514950166112955 best: -2.5182724252491693 10\n",
      "It took 5.711945904999084 seconds to complete generation 31\n",
      "Step 32.0 : -2.564784053156146 best: -2.5182724252491693 10\n",
      "It took 5.620913695000127 seconds to complete generation 32\n",
      "Step 33.0 : -2.5714285714285716 best: -2.5182724252491693 10\n",
      "It took 7.3585361469995405 seconds to complete generation 33\n",
      "Step 34.0 : -2.5714285714285716 best: -2.5182724252491693 10\n",
      "It took 7.117637552000815 seconds to complete generation 34\n",
      "Step 35.0 : -2.5847176079734218 best: -2.5182724252491693 10\n",
      "It took 9.828544391000833 seconds to complete generation 35\n",
      "Step 36.0 : -2.558139534883721 best: -2.5182724252491693 10\n",
      "It took 8.231641954000224 seconds to complete generation 36\n",
      "Step 37.0 : -2.5946843853820596 best: -2.5182724252491693 10\n",
      "It took 6.988106581000466 seconds to complete generation 37\n",
      "Step 38.0 : -2.548172757475083 best: -2.5182724252491693 10\n",
      "It took 5.989308043999699 seconds to complete generation 38\n",
      "Step 39.0 : -2.6279069767441863 best: -2.5182724252491693 10\n",
      "It took 5.92410661500071 seconds to complete generation 39\n",
      "Step 40.0 : -2.548172757475083 best: -2.5182724252491693 10\n",
      "It took 6.000529122000444 seconds to complete generation 40\n",
      "Test accuracy on target: 0.1444\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of weights to evolve is:\", weights.shape)\n",
    "all_examples_indices = list(range(x_train.shape[0]))\n",
    "clf, _ = train_classifier(model, x_train, y_train)\n",
    "y_pred = predict_classifier(model, clf, x_test)\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Non-trained NN Test accuracy:', test_accuracy)\n",
    "# print('Test MSE:', test_mse)\n",
    "\n",
    "snes = SNES(weights, 1, POPULATION_SIZE)\n",
    "p = []\n",
    "for i in range(0, GENERATIONS):\n",
    "    start = timer()\n",
    "    asked = snes.ask()\n",
    "\n",
    "    # to be provided back to snes\n",
    "    told = []\n",
    "\n",
    "    # use a small number of training samples for speed purposes\n",
    "    subsample_indices = np.random.choice(all_examples_indices, size=SAMPLE_SIZE, replace=False)\n",
    "    # evaluate on another subset\n",
    "    subsample_indices_valid = np.random.choice(all_examples_indices, size=SAMPLE_SIZE + 1, replace=False)\n",
    "\n",
    "    # iterate over the population\n",
    "    for asked_j in asked:\n",
    "        # set nn weights\n",
    "        nnw.set_weights(asked_j)\n",
    "        # train the label classifer and get back the predictions on the training data\n",
    "        clf, _ = train_classifier(model, x_train[subsample_indices], y_train[subsample_indices])\n",
    "        # train the domain classifier and get back the predictions on the training data\n",
    "        clf2, _ = train_classifier(model, x_domain[subsample_indices], y_domain[subsample_indices])\n",
    "\n",
    "        # calculate the label predictions on a different set\n",
    "        y_pred = predict_classifier(model, clf, x_train[subsample_indices_valid])\n",
    "        score = accuracy_score(y_train[subsample_indices_valid], y_pred)\n",
    "\n",
    "        # calculate the domain predictions on a different set\n",
    "        y_pred2 = predict_classifier(model, clf2, x_domain[subsample_indices_valid])\n",
    "        score2 = accuracy_score(y_domain[subsample_indices_valid], y_pred2)\n",
    "        \n",
    "        # weighted score to give back to snes\n",
    "        total = (score - (3*score2))\n",
    "        told.append(total)\n",
    "\n",
    "    temp = snes.tell(asked, told)\n",
    "    p.append(temp)\n",
    "    end = timer()\n",
    "    print(\"It took\", end - start, \"seconds to complete generation\", i + 1)\n",
    "    \n",
    "nnw.set_weights(snes.center)\n",
    "\n",
    "# predict on target data\n",
    "clf, _ = train_classifier(model, x_train, y_train)\n",
    "y_pred = predict_classifier(model, clf, x_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Test accuracy on target:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa523de6b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print loss plot\n",
    "plt.plot(p)\n",
    "plt.title('Loss Plot')\n",
    "plt.xlabel('generation')\n",
    "plt.ylabel('value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
